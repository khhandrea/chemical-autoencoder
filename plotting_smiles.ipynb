{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# tensorflow backend\r\n",
    "print('tensorflow backend')\r\n",
    "from os import environ\r\n",
    "environ['KERAS_BACKEND'] = 'tensorflow'\r\n",
    "# vae stuff\r\n",
    "print('vae stuff')\r\n",
    "from chemvae.vae_utils import VAEUtils\r\n",
    "from chemvae import mol_utils as mu\r\n",
    "# import scientific py\r\n",
    "print('iport scientific py')\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "# rdkit stuff\r\n",
    "print('rdkit stuff')\r\n",
    "from rdkit.Chem import AllChem as Chem\r\n",
    "from rdkit.Chem import PandasTools\r\n",
    "# plotting stuff\r\n",
    "print('plotting stuff')\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib as mpl\r\n",
    "from IPython.display import SVG, display\r\n",
    "%config InlineBackend.figure_format = 'retina'\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "from sklearn.datasets import load_digits\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensorflow backend\n",
      "vae stuff\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iport scientific py\n",
      "rdkit stuff\n",
      "plotting stuff\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "vae = VAEUtils(directory='models/zinc_properties')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1210: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\models.py:245: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1156: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using standarized functions? True\n",
      "Standarization: estimating mu and std values ...done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load smiles"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "smiles_group = []\r\n",
    "is_count = 0\r\n",
    "is_not_count = 0\r\n",
    "df = pd.read_csv('./ask1_smiles.csv')\r\n",
    "df.drop(['index'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    if(df.loc[i, 'smiles'].find('.') == -1 and df.loc[i, 'smiles'].find('i') == -1):\r\n",
    "        is_not_count += 1\r\n",
    "        smiles_group.append([df.loc[i, 'smiles'], df.loc[i, 'activation']])\r\n",
    "    else:\r\n",
    "        is_count += 1\r\n",
    "\r\n",
    "print('molcule fetched :', len(df))\r\n",
    "print('invalid molecule detected :', is_count)\r\n",
    "print('valid molecule detected :', is_not_count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "molcule fetched : 21909\n",
      "invalid molecule detected : 3155\n",
      "valid molecule detected : 18754\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decode latent space / fingerprint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# bytes to bits\r\n",
    "def access_bit(data, num):\r\n",
    "    base = int(num // 8)\r\n",
    "    shift = int(num % 8)\r\n",
    "    return (data[base] & (1<<shift)) >> shift\r\n",
    "\r\n",
    "def smiles_to_vect(smiles_group):\r\n",
    "    smiles_list = [ mu.canon_smiles(data[0]) for data in smiles_group ]\r\n",
    "\r\n",
    "    # latent spcae\r\n",
    "    print('(1/5) encoding latent space...')\r\n",
    "    Xs = [ (vae.smiles_to_hot(smiles, canonize_smiles=True)) for smiles in smiles_list ]\r\n",
    "    Zs = [ list(vae.encode(X)[0]) for X in Xs ]\r\n",
    "    latent_group.extend(list(zip(Zs, [ data[1] for data in smiles_group ])))\r\n",
    "    \r\n",
    "    # mols = [ Chem.MolFromSmiles(smiles) for smiles in smiles_list ]\r\n",
    "\r\n",
    "    # # rdk fp\r\n",
    "    # print('\\r(2/5) encoding rdk fp...')\r\n",
    "    # fps = [ Chem.RDKFingerprint(mol) for mol in mols ]\r\n",
    "    # fpBits = [ [ int(char) for char in fp.ToBitString() ] for fp in fps ]\r\n",
    "    # rdk_fp_group.extend(list(zip(fpBits, [ data[1] for data in smiles_group ])))\r\n",
    "\r\n",
    "    # # pattern fp\r\n",
    "    # print('\\r(3/5) encoding pattern fp...')\r\n",
    "    # fps = [ Chem.PatternFingerprint(mol) for mol in mols ]\r\n",
    "    # fpBits = [ [ int(char) for char in fp.ToBitString() ] for fp in fps ]\r\n",
    "    # pattern_fp_group.extend(list(zip(fpBits, [ data[1] for data in smiles_group ])))\r\n",
    "\r\n",
    "    # # layered fp\r\n",
    "    # print('\\r(4/5) encoding layered fp...')\r\n",
    "    # fps = [ Chem.LayeredFingerprint(mol) for mol in mols ]\r\n",
    "    # fpBits = [ [ int(char) for char in fp.ToBitString() ] for fp in fps ]\r\n",
    "    # layered_fp_group.extend(list(zip(fpBits, [ data[1] for data in smiles_group ])))\r\n",
    "\r\n",
    "    # # MACCSKeys fp\r\n",
    "    # print('\\r(5/5) encoding layered fp...')\r\n",
    "    # fps = [ Chem.GetMACCSKeysFingerprint(mol) for mol in mols ]\r\n",
    "    # fpBits = [ [ int(char) for char in fp.ToBitString() ] for fp in fps ]\r\n",
    "    # MACCSKeys_fp_group.extend(list(zip(fpBits, [ data[1] for data in smiles_group ])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert smiles to coordinates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "latent_group = []\r\n",
    "rdk_fp_group = []\r\n",
    "pattern_fp_group = []\r\n",
    "layered_fp_group = []\r\n",
    "MACCSKeys_fp_group = []\r\n",
    "smiles_to_vect(smiles_group)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1/5) encoding latent space...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save latent/fingerprint data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df = pd.DataFrame(latent_group)\r\n",
    "df.to_csv('./data/latent_group.csv')\r\n",
    "\r\n",
    "# df = pd.DataFrame(rdk_fp_group)\r\n",
    "# df.to_csv('./data/rdk_fp_group.csv')\r\n",
    "\r\n",
    "# df = pd.DataFrame(pattern_fp_group)\r\n",
    "# df.to_csv('./data/pattern_fp_group.csv')\r\n",
    "\r\n",
    "# df = pd.DataFrame(layered_fp_group)\r\n",
    "# df.to_csv('./data/layered_fp_group.csv')\r\n",
    "\r\n",
    "# df = pd.DataFrame(MACCSKeys_fp_group)\r\n",
    "# df.to_csv('./data/MACCKeys_fp_group.csv')\r\n",
    "\r\n",
    "# take about 60s."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load latent/fingerprint data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print('(1/5) fetching latent space group...')\r\n",
    "latent_group = []\r\n",
    "df = pd.read_csv('./data/latent_group.csv')\r\n",
    "df.drop(['0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(float, df.loc[i, '1'].strip('[]').split(', ')))\r\n",
    "    latent_group.append([points, df.loc[i, '2']])\r\n",
    "\r\n",
    "print('(2/5) fetching rdk fp group...')\r\n",
    "rdk_fp_group = []\r\n",
    "df = pd.read_csv('./data/rdk_fp_group.csv')\r\n",
    "df.drop(['0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(int, df.loc[i, '1'].strip('[]').split(', ')))\r\n",
    "    rdk_fp_group.append([points, df.loc[i, '2']])\r\n",
    "\r\n",
    "print('(3/5) fetching pattern fp group...')\r\n",
    "pattern_fp_group = []\r\n",
    "df = pd.read_csv('./data/pattern_fp_group.csv')\r\n",
    "df.drop(['0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(float, df.loc[i, '1'].strip('[]').split(', ')))\r\n",
    "    pattern_fp_group.append([points, df.loc[i, '2']])\r\n",
    "\r\n",
    "print('(4/5) fetching layered fp group...')\r\n",
    "layered_fp_group = []\r\n",
    "df = pd.read_csv('./data/layered_fp_group.csv')\r\n",
    "df.drop(['0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(float, df.loc[i, '1'].strip('[]').split(', ')))\r\n",
    "    layered_fp_group.append([points, df.loc[i, '2']])\r\n",
    "\r\n",
    "print('(5/5) fetching MACCSKeys fp group...')\r\n",
    "MACCSKeys_fp_group = []\r\n",
    "df = pd.read_csv('./data/MACCSKeys_fp_group.csv')\r\n",
    "df.drop(['0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(float, df.loc[i, '1'].strip('[]').split(', ')))\r\n",
    "    MACCSKeys_fp_group.append([points, df.loc[i, '2']])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1/5) fetching latent space group...\n",
      "(2/5) fetching rdk fp group...\n",
      "(3/5) fetching pattern fp group...\n",
      "(4/5) fetching layered fp group...\n",
      "(5/5) fetching MACCSKeys fp group...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build DimReduction Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "n_components = 2\r\n",
    "model_pca = PCA(n_components=n_components)\r\n",
    "model_tsne = TSNE(n_components=n_components)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and Save DimReduction Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# print('\\r(1/10) {:30s}'.format('training latent tsne...'))\r\n",
    "# points_latent_tsne = model_tsne.fit_transform([ points[0] for points in latent_group ])\r\n",
    "# df = pd.DataFrame(points_latent_tsne)\r\n",
    "# df.to_csv('./data/points_latent_tsne.csv')\r\n",
    "\r\n",
    "# print('\\r(2/10) {:30s}'.format('training latent pca...'))\r\n",
    "# points_latent_pca = model_pca.fit_transform([ points[0] for points in latent_group ])\r\n",
    "# df = pd.DataFrame(points_latent_pca)\r\n",
    "# df.to_csv('./data/points_latent_pca.csv')\r\n",
    "\r\n",
    "# print('\\r(3/10) {:30s}'.format('training rdk fingerprint tsne...'))\r\n",
    "# points_rdk_fp_tsne = model_tsne.fit_transform([ points[0] for points in rdk_fp_group ])\r\n",
    "# df = pd.DataFrame(points_rdk_fp_tsne)\r\n",
    "# df.to_csv('./data/points_rdk_fp_tsne.csv')\r\n",
    "\r\n",
    "\r\n",
    "# print('\\r(4/10) {:30s}'.format('training rdk fingerprint pca...'))\r\n",
    "# points_rdk_fp_pca = model_pca.fit_transform([ points[0] for points in rdk_fp_group ])\r\n",
    "# df = pd.DataFrame(points_rdk_fp_pca)\r\n",
    "# df.to_csv('./data/points_rdk_fp_pca.csv')\r\n",
    "\r\n",
    "# print('\\r(5/10) {:30s}'.format('training pattern fingerprint tsne...'))\r\n",
    "# points_pattern_fp_tsne = model_tsne.fit_transform([ points[0] for points in pattern_fp_group ])\r\n",
    "# df = pd.DataFrame(points_pattern_fp_tsne)\r\n",
    "# df.to_csv('./data/points_pattern_fp_tsne.csv')\r\n",
    "\r\n",
    "# print('\\r(6/10) {:30s}'.format('training pattern fingerprint pca...'))\r\n",
    "# points_pattern_fp_pca = model_pca.fit_transform([ points[0] for points in pattern_fp_group ])\r\n",
    "# df = pd.DataFrame(points_pattern_fp_pca)\r\n",
    "# df.to_csv('./data/points_pattern_fp_pca.csv')\r\n",
    "\r\n",
    "# print('\\r(7/10) {:30s}'.format('training layered fingerprint tsne...'))\r\n",
    "# points_layered_fp_tsne = model_tsne.fit_transform([ points[0] for points in layered_fp_group ])\r\n",
    "# df = pd.DataFrame(points_layered_fp_tsne)\r\n",
    "# df.to_csv('./data/points_layered_fp_tsne.csv')\r\n",
    "\r\n",
    "# print('\\r(8/10) {:30s}'.format('training layered fingerprint pca...'))\r\n",
    "# points_layered_fp_pca = model_pca.fit_transform([ points[0] for points in layered_fp_group ])\r\n",
    "# df = pd.DataFrame(points_layered_fp_pca)\r\n",
    "# df.to_csv('./data/points_layered_fp_pca.csv')\r\n",
    "\r\n",
    "# print('\\r(9/10) {:30s}'.format('training MACCSKeys fingerprint tsne...'))\r\n",
    "# points_MACCSKeys_fp_tsne = model_tsne.fit_transform([ points[0] for points in MACCSKeys_fp_group ])\r\n",
    "# df = pd.DataFrame(points_MACCSKeys_fp_tsne)\r\n",
    "# df.to_csv('./data/points_MACCSKeys_fp_tsne.csv')\r\n",
    "\r\n",
    "# print('\\r(10/10) {:30s}'.format('training MACCSKeys fingerprint pca...'))\r\n",
    "# points_MACCSKeys_fp_pca = model_pca.fit_transform([ points[0] for points in MACCSKeys_fp_group ])\r\n",
    "# df = pd.DataFrame(points_MACCSKeys_fp_pca)\r\n",
    "# df.to_csv('./data/points_MACCSKeys_fp_pca.csv')\r\n",
    "\r\n",
    "\r\n",
    "# takes about 1200s."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load coordinates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('(0/10) fetching latent space group...')\r\n",
    "latent_group = []\r\n",
    "df = pd.read_csv('./data/latent_group.csv')\r\n",
    "df.drop(['0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(float, df.loc[i, '1'].strip('[]').split(', ')))\r\n",
    "    latent_group.append([points, df.loc[i, '2']])\r\n",
    "\r\n",
    "print('(1/10) fetching latent space tsne points...')\r\n",
    "points_latent_tsne = []\r\n",
    "df = pd.read_csv('./data/points_latent_tsne.csv')\r\n",
    "for i in range(len(df)):\\\r\n",
    "    points_latent_tsne.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "\r\n",
    "print('(2/10) fetching latent space pca points...')\r\n",
    "points_latent_pca = []\r\n",
    "df = pd.read_csv('./data/points_latent_pca.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_latent_pca.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "\r\n",
    "print('(3/10) fetching rdk fingerprint tsne points...')\r\n",
    "points_rdk_fp_tsne = []\r\n",
    "df = pd.read_csv('./data/points_rdk_fp_tsne.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_rdk_fp_tsne.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "    \r\n",
    "print('(4/10) fetching rdk fingerprint pca points...')\r\n",
    "points_rdk_fp_pca = []\r\n",
    "df = pd.read_csv('./data/points_rdk_fp_pca.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_rdk_fp_pca.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "\r\n",
    "print('(5/10) fetching pattern fingerprint tsne points...')\r\n",
    "points_pattern_fp_tsne = []\r\n",
    "df = pd.read_csv('./data/points_pattern_fp_tsne.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_pattern_fp_tsne.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "    \r\n",
    "print('(6/10) fetching pattern fingerprint pca points...')\r\n",
    "points_pattern_fp_pca = []\r\n",
    "df = pd.read_csv('./data/points_pattern_fp_pca.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_pattern_fp_pca.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "\r\n",
    "print('(7/10) fetching layered fingerprint tsne points...')\r\n",
    "points_layered_fp_tsne = []\r\n",
    "df = pd.read_csv('./data/points_layered_fp_tsne.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_layered_fp_tsne.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "    \r\n",
    "print('(8/10) fetching layered fingerprint pca points...')\r\n",
    "points_layered_fp_pca = []\r\n",
    "df = pd.read_csv('./data/points_layered_fp_pca.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_layered_fp_pca.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "\r\n",
    "print('(9/10) fetching MACCSKeys fingerprint tsne points...')\r\n",
    "points_MACCSKeys_fp_tsne = []\r\n",
    "df = pd.read_csv('./data/points_MACCSKeys_fp_tsne.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_MACCSKeys_fp_tsne.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))\r\n",
    "    \r\n",
    "print('(10/10) fetching MACCSKeys fingerprint pca points...')\r\n",
    "points_MACCSKeys_fp_pca = []\r\n",
    "df = pd.read_csv('./data/points_MACCSKeys_fp_pca.csv')\r\n",
    "for i in range(len(df)):\r\n",
    "    points_MACCSKeys_fp_pca.append(list(map(float, [df.loc[i, '0'], df.loc[i, '1']])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0/10) fetching latent space group...\n",
      "(1/10) fetching latent space tsne points...\n",
      "(2/10) fetching latent space pca points...\n",
      "(3/10) fetching rdk fingerprint tsne points...\n",
      "(4/10) fetching rdk fingerprint pca points...\n",
      "(5/10) fetching pattern fingerprint tsne points...\n",
      "(6/10) fetching pattern fingerprint pca points...\n",
      "(7/10) fetching layered fingerprint tsne points...\n",
      "(8/10) fetching layered fingerprint pca points...\n",
      "(9/10) fetching MACCSKeys fingerprint tsne points...\n",
      "(10/10) fetching MACCSKeys fingerprint pca points...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x1 = [ point[0] for point in points_latent_pca ]\r\n",
    "y1 = [ point[1] for point in points_latent_pca ]\r\n",
    "\r\n",
    "x2 = [ point[0] for point in points_latent_tsne ]\r\n",
    "y2 = [ point[1] for point in points_latent_tsne ]\r\n",
    "\r\n",
    "x3 = [ point[0] for point in points_rdk_fp_pca ]\r\n",
    "y3 = [ point[1] for point in points_rdk_fp_pca ]\r\n",
    "\r\n",
    "x4 = [ point[0] for point in points_rdk_fp_tsne ]\r\n",
    "y4 = [ point[1] for point in points_rdk_fp_tsne ]\r\n",
    "\r\n",
    "x5 = [ point[0] for point in points_pattern_fp_pca ]\r\n",
    "y5 = [ point[1] for point in points_pattern_fp_pca ]\r\n",
    "\r\n",
    "x6 = [ point[0] for point in points_pattern_fp_tsne ]\r\n",
    "y6 = [ point[1] for point in points_pattern_fp_tsne ]\r\n",
    "\r\n",
    "x7 = [ point[0] for point in points_layered_fp_pca ]\r\n",
    "y7 = [ point[1] for point in points_layered_fp_pca ]\r\n",
    "\r\n",
    "x8 = [ point[0] for point in points_layered_fp_tsne ]\r\n",
    "y8 = [ point[1] for point in points_layered_fp_tsne ]\r\n",
    "\r\n",
    "x9 = [ point[0] for point in points_MACCSKeys_fp_pca ]\r\n",
    "y9 = [ point[1] for point in points_MACCSKeys_fp_pca ]\r\n",
    "\r\n",
    "x10 = [ point[0] for point in points_MACCSKeys_fp_tsne ]\r\n",
    "y10 = [ point[1] for point in points_MACCSKeys_fp_tsne ]\r\n",
    "\r\n",
    "target = [ item[1] for item in latent_group ]\r\n",
    "count = 0\r\n",
    "for t in target:\r\n",
    "    count += t\r\n",
    "\r\n",
    "alpha1 = 1.0\r\n",
    "alpha0 = 0.5\r\n",
    "size1 = 5\r\n",
    "size0 = 5\r\n",
    "color1 = '#e84393'\r\n",
    "color0 = '#74b9ff'\r\n",
    "bg_color = '#CAD3C8'\r\n",
    "fontsize = 30\r\n",
    "\r\n",
    "cmap = plt.cm.get_cmap('cool', 2)\r\n",
    "\r\n",
    "fig, ax = plt.subplots(5, 2)\r\n",
    "fig.set_size_inches((40, 16))\r\n",
    "plt.rcParams['axes.facecolor'] = bg_color\r\n",
    "\r\n",
    "plt.subplot(251)\r\n",
    "plt.scatter(x1[count:], y1[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x1[:count], y1[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('latent PCA', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(252)\r\n",
    "plt.scatter(x2[count:], y2[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x2[:count], y2[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('latent TSNE', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(253)\r\n",
    "plt.scatter(x3[count:], y3[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x3[:count], y3[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('rdk fingerprint PCA', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(254)\r\n",
    "plt.scatter(x4[count:], y4[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x4[:count], y4[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('rdk fingerprint TNSE', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(255)\r\n",
    "plt.scatter(x5[count:], y5[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x5[:count], y5[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('pattern fingerprint PCA', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(256)\r\n",
    "plt.scatter(x6[count:], y6[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x6[:count], y6[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('pattern fingerprint TNSE', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(257)\r\n",
    "plt.scatter(x7[count:], y7[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x7[:count], y7[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('layered fingerprint PCA', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(258)\r\n",
    "plt.scatter(x8[count:], y8[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x8[:count], y8[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('layered fingerprint TNSE', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(259)\r\n",
    "plt.scatter(x9[count:], y9[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x9[:count], y9[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('MACCSKeys fingerprint PCA', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(2, 5,10)\r\n",
    "plt.scatter(x10[count:], y10[count:], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x10[:count], y10[:count], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('MACCKeys fingerprint TNSE', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('01_chemvae': conda)"
  },
  "interpreter": {
   "hash": "111b6f304afb9dfb3ff29c259c88395a47b4de97d591c8d68e14d97f5211ad2a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}