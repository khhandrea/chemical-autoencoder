{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# tensorflow backend\r\n",
    "print('tensorflow backend')\r\n",
    "from os import environ\r\n",
    "environ['KERAS_BACKEND'] = 'tensorflow'\r\n",
    "# vae stuff\r\n",
    "print('vae stuff')\r\n",
    "from chemvae.vae_utils import VAEUtils\r\n",
    "from chemvae import mol_utils as mu\r\n",
    "# import scientific py\r\n",
    "print('iport scientific py')\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "# rdkit stuff\r\n",
    "print('rdkit stuff')\r\n",
    "from rdkit.Chem import AllChem as Chem\r\n",
    "from rdkit.Chem import PandasTools\r\n",
    "# plotting stuff\r\n",
    "print('plotting stuff')\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib as mpl\r\n",
    "from IPython.display import SVG, display\r\n",
    "%config InlineBackend.figure_format = 'retina'\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "from sklearn.datasets import load_digits\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np \r\n",
    "\r\n",
    "import pandas as pd"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensorflow backend\n",
      "vae stuff\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iport scientific py\n",
      "rdkit stuff\n",
      "plotting stuff\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load a model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "vae = VAEUtils(directory='models/zinc_properties')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1210: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\models.py:245: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1156: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using standarized functions? True\n",
      "Standarization: estimating mu and std values ...done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load smiles"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "smiles_group = []\r\n",
    "df = pd.read_csv('./data/mao/mao_smiles.csv')\r\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
    "smiles_group = (df.columns.values.tolist() + df.values.tolist())[2:]\r\n",
    "\r\n",
    "df = pd.read_csv('./data/mao/asinex_smiles.csv')\r\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
    "smiles_group.extend((df.columns.values.tolist() + df.values.tolist())[2:])\r\n",
    "print('molcule fetched :', len(smiles_group))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "molcule fetched : 138917\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decode latent space / fingerprint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# bytes to bits\r\n",
    "def access_bit(data, num):\r\n",
    "    base = int(num // 8)\r\n",
    "    shift = int(num % 8)\r\n",
    "    return (data[base] & (1<<shift)) >> shift\r\n",
    "\r\n",
    "def smiles_to_vect(smiles_group):\r\n",
    "    print('# of smiles group:', len(smiles_group))\r\n",
    "    \r\n",
    "    print('canonizing smiles...')\r\n",
    "    smiles_list = [ mu.canon_smiles(data[0]) for data in smiles_group ]\r\n",
    "    \r\n",
    "    print('encoding mols to hot...')\r\n",
    "    Xs = []\r\n",
    "    count = 0\r\n",
    "    for idx, smiles in enumerate(smiles_list):\r\n",
    "        try:\r\n",
    "            Xs.append(vae.smiles_to_hot(smiles, canonize_smiles=True))\r\n",
    "        except:\r\n",
    "            count += 1\r\n",
    "            del smiles_group[idx]\r\n",
    "    print('failed:', count)\r\n",
    "    print('# of smiles group:', len(smiles_group))\r\n",
    "\r\n",
    "    print('encoding mols...')\r\n",
    "    Zs = []\r\n",
    "    count = 0\r\n",
    "    for idx, X in enumerate(Xs):\r\n",
    "        try:\r\n",
    "            Zs.append(list(vae.encode(X)[0]))\r\n",
    "        except:\r\n",
    "            count += 1\r\n",
    "            del smiles_group[idx]\r\n",
    "    print('failed:', count)\r\n",
    "    print('# of smiles group:', len(smiles_group))\r\n",
    "    \r\n",
    "    latent_group.extend(list(zip(Zs, [ data[1] for data in smiles_group ])))\r\n",
    "    \r\n",
    "    mols = [ Chem.MolFromSmiles(smiles) for smiles in smiles_list ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert smiles to coordinates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "latent_group = []\r\n",
    "smiles_to_vect(smiles_group)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of smiles group: 138917\n",
      "canonizing smiles...\n",
      "encoding mols to hot...\n",
      "failed: 203\n",
      "# of smiles group: 138714\n",
      "encoding mols...\n",
      "failed: 85\n",
      "# of smiles group: 138629\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save latent data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df = pd.DataFrame(latent_group)\r\n",
    "df.to_csv('./data/mao/latent_group.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load latent data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "print('fetching latent space group...')\r\n",
    "latent_group = []\r\n",
    "df = pd.read_csv('./data/mao/latent_group.csv')\r\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
    "for i in range(len(df)):\r\n",
    "    points = list(map(float, df.loc[i, '0'].strip('[]').split(', ')))\r\n",
    "    latent_group.append([points, df.loc[i, '1']])\r\n",
    "print('# of fetched data:', len(latent_group))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fetching latent space group...\n",
      "# of fetched data: 138629\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build DimReduction Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "n_components = 2\r\n",
    "model_pca = PCA(n_components=n_components)\r\n",
    "model_tsne = TSNE(n_components=n_components)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and Save DimReduction Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "print('\\r(1/2) {:30s}'.format('training latent pca...'))\r\n",
    "points_latent_pca = model_pca.fit_transform([ points[0] for points in latent_group ])\r\n",
    "df = pd.DataFrame(points_latent_pca)\r\n",
    "df.to_csv('./data/mao/points_latent_pca.csv')\r\n",
    "\r\n",
    "print('\\r(2/2) {:30s}'.format('training latent tsne...'))\r\n",
    "points_latent_tsne = model_tsne.fit_transform([ points[0] for points in latent_group ])\r\n",
    "df = pd.DataFrame(points_latent_tsne)\r\n",
    "df.to_csv('./data/mao/points_latent_tsne.csv')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2/2) training latent tsne...       \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load coordinates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print('(0/2) fetching latent space group...')\r\n",
    "latent_target_group = []\r\n",
    "df = pd.read_csv('./data/mao/latent_group.csv')\r\n",
    "latent_target_group = df['1'].values.tolist()\r\n",
    "print('data fetched:', len(latent_target_group))\r\n",
    "\r\n",
    "print('(1/2) fetching latent space tsne points...')\r\n",
    "points_latent_tsne = []\r\n",
    "df = pd.read_csv('./data/mao/points_latent_tsne.csv')\r\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
    "points_latent_tsne = df.values.tolist()\r\n",
    "print('data fetched:', len(points_latent_tsne))\r\n",
    "\r\n",
    "print('(2/2) fetching latent space pca points...')\r\n",
    "points_latent_pca = []\r\n",
    "df = pd.read_csv('./data/mao/points_latent_pca.csv')\r\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\r\n",
    "points_latent_pca = df.values.tolist()\r\n",
    "print('data fetched:', len(points_latent_pca))\r\n",
    "\r\n",
    "# sort loaded data\r\n",
    "sorted = list(zip(latent_target_group, points_latent_pca, points_latent_tsne))\r\n",
    "sorted.sort(key=lambda x:x[0])\r\n",
    "latent_target_group = list(np.array(sorted, dtype=object).T[0])\r\n",
    "points_latent_pca = list(np.array(sorted, dtype=object).T[1])\r\n",
    "points_latent_tsne = list(np.array(sorted, dtype=object).T[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0/2) fetching latent space group...\n",
      "data fetched: 138629\n",
      "(1/2) fetching latent space tsne points...\n",
      "data fetched: 138629\n",
      "(2/2) fetching latent space pca points...\n",
      "data fetched: 138629\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\r\n",
    "x1 = [ point[0] for point in points_latent_pca ]\r\n",
    "y1 = [ point[1] for point in points_latent_pca ]\r\n",
    "\r\n",
    "x2 = [ point[0] for point in points_latent_tsne ]\r\n",
    "y2 = [ point[1] for point in points_latent_tsne ]\r\n",
    "\r\n",
    "count = 0\r\n",
    "for t in latent_target_group[::-1]:\r\n",
    "    if t == 1:\r\n",
    "        count += 1\r\n",
    "    else:\r\n",
    "        break\r\n",
    "\r\n",
    "alpha1 = 1.0 \r\n",
    "alpha0 = 0.5\r\n",
    "size1 = 5\r\n",
    "size0 = 5\r\n",
    "color1 = '#e84393'\r\n",
    "color0 = '#74b9ff'\r\n",
    "bg_color = '#ffffff' # '#CAD3C8'\r\n",
    "fontsize = 30\r\n",
    "\r\n",
    "cmap = plt.cm.get_cmap('cool', 2)\r\n",
    "\r\n",
    "fig, ax = plt.subplots(1, 2)\r\n",
    "fig.set_size_inches((18, 9))\r\n",
    "plt.rcParams['axes.facecolor'] = bg_color\r\n",
    "\r\n",
    "plt.subplot(121)\r\n",
    "plt.scatter(x1[:-count], y1[:-count], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x1[-count:], y1[-count:], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('latent PCA', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.subplot(122)\r\n",
    "plt.scatter(x2[:-count], y2[:-count], c=color0, s=size0, alpha=alpha0)\r\n",
    "plt.scatter(x2[-count:], y2[-count:], c=color1, s=size1, alpha=alpha1)\r\n",
    "plt.title('latent TSNE', fontsize=fontsize)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'points_rdk_fp_pca' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-30c34baa8d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoints_latent_tsne\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoints_rdk_fp_pca\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoints_rdk_fp_pca\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'points_rdk_fp_pca' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('01_chemvae': conda)"
  },
  "interpreter": {
   "hash": "111b6f304afb9dfb3ff29c259c88395a47b4de97d591c8d68e14d97f5211ad2a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}