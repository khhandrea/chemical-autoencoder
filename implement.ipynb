{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup proejct"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "project = input('input project name ')\r\n",
    "directory = './' + project\r\n",
    "try:\r\n",
    "    if not os.path.exists(directory):\r\n",
    "        os.makedirs(directory)\r\n",
    "        os.makedirs(directory + '/data')\r\n",
    "        print('project created :', project)\r\n",
    "    else:\r\n",
    "        print('project with the same name already exists :', project)\r\n",
    "except OSError:\r\n",
    "    print('Error : Creating directory', directory)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "project with the same name already exists : test\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (option 1) Fetch several data from smiles.sd"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from implements.fetcher import fetch_sd\r\n",
    "\r\n",
    "# number = int(input('enter a number of data')) \r\n",
    "# fetch_sd(project, number)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (option 2) Fetch data from *.csv\r\n",
    "* need 'smiles.csv' with columns 'smiles, label'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# from implements.fetcher import fetch_csv\r\n",
    "\r\n",
    "# smiles = fetch_csv(project)\r\n",
    "# print(smiles)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode molecules to latent space & fingerprints"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from implements.encoder import encode_latent_fp\r\n",
    "\r\n",
    "encode_latent_fp(project)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensorflow backend\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fetching data...\n",
      "fetched smiles : 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1210: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\models.py:245: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "From C:\\Users\\PC\\.conda\\envs\\01_chemvae\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1156: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using standarized functions? True\n",
      "Standarization: estimating mu and std values ...done!\n",
      "canonizing smiles...\n",
      "encoding mols to hot...\n",
      "failed :  1\n",
      "encoded smiles : 7\n",
      "encoding mols...\n",
      "failed: 0\n",
      "encoded smiles : 7\n",
      "encoding rdk fp...\n",
      "[<rdkit.Chem.rdchem.Mol object at 0x000001758FA874E0>, <rdkit.Chem.rdchem.Mol object at 0x00000175A336B300>, <rdkit.Chem.rdchem.Mol object at 0x00000175A336B170>, <rdkit.Chem.rdchem.Mol object at 0x00000175A336B6C0>, <rdkit.Chem.rdchem.Mol object at 0x000001759A6D9E90>, <rdkit.Chem.rdchem.Mol object at 0x000001759A6D9B20>, <rdkit.Chem.rdchem.Mol object at 0x000001759A6D9DA0>, <rdkit.Chem.rdchem.Mol object at 0x000001759A6D9C10>]\n",
      "encoding pattern fp...\n",
      "encoding layered fp...\n",
      "encoding layered fp...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch external latent space & fingerprints\r\n",
    "* need 'external_points_latent_space.csv' or 'external_points_(fingerprint)_fp_csv'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# from implements.fetcher import fetch_latent_space\r\n",
    "# from implements.fetcher import fetch_fingerprints\r\n",
    "\r\n",
    "# fetch_latent_space(project)\r\n",
    "# fetch_fingerprints(project)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check GPU"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tensorflow.python.client import device_lib\r\n",
    "print(device_lib.list_local_devices())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1936159211036128799\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  tSNE & PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from implements.learner import learn_tsne_pca\r\n",
    "\r\n",
    "learn_tsne_pca('test')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5/5) fetching MACCSKeys fp group...\n",
      "(10/10) training MACCSKeys fingerprint pca..."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot molecules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from implements.plotter import plot_molecules\r\n",
    "\r\n",
    "plot_molecules('test')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1/10) fetching latent space tsne points...\n",
      "(2/10) fetching latent space pca points...\n",
      "(3/10) fetching rdk fingerprint tsne points...\n",
      "(4/10) fetching rdk fingerprint pca points...\n",
      "(5/10) fetching pattern fingerprint tsne points...\n",
      "(6/10) fetching pattern fingerprint pca points...\n",
      "(7/10) fetching layered fingerprint tsne points...\n",
      "(8/10) fetching layered fingerprint pca points...\n",
      "(9/10) fetching MACCSKeys fingerprint tsne points...\n",
      "(10/10) fetching MACCSKeys fingerprint pca points...\n",
      "[['CC1=CC(=NC(=N1)NC2=CC=C(C=C2)N3CCOCC3)NC4=CC5=C(C=C4)OCO5', -0.2138673904117813, -2.341407566157262], ['CC1=CC(=NC(=N1)NC2=CC(=CC=C2)N(C)C)NCCC3=CC=C(C=C3)OC', -2.322728944272864, 1.479516853773363], ['CC(=O)NC1=CC=C(C=C1)NC2=NC(=NC3=CC(=C(C=C32)OC)OC)NC4=NC=CC5=CC=CC=C54', -0.3376685923581338, 2.7834695118061124], ['CN1C2=CC=CC=C2N=C1NC3=NC4=CC(=C(C=C4C(=N3)NC5=CC=C(C=C5)N6CCOCC6)OC)OC', 4.740551535423183, 0.8175415983694776], ['COC1=C(C=C2C(=C1)C(=NC(=N2)NC3=CC=C(C=C3)N4CCOCC4)NC5=CC=C(C=C5)N6CCOCC6)OC', -0.25417023001476435, -1.6617824328058208], ['CC1=CC(=NC(=N1)NC2=CC(=CC=C2)N(C)C)NC3=CC4=C(C=C3)OCO4', -0.13309663006944722, -1.4976499589402532], ['CC1=CN=C(N=C1NC2=CC(=C(C(=C2)OC)OC)OC)C3=CC=C(C=C3)C(=O)N', -1.479019748296192, 0.4203119939543842]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select and cluster the molecules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from implements.plotter import cluster\r\n",
    "\r\n",
    "sel = input('select graph to be clustered')\r\n",
    "clustered = cluster(project, sel) # cluster, plot, display"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cluster! plot! display!\n",
      "project test complete\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export the molecules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from implements.plotter import export_molecules\r\n",
    "\r\n",
    "sel = list(map(int, input('enter label numbers to export').split(' ')))\r\n",
    "export_molecules(project, clustered, sel)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "export test\n",
      "clustered : 4 5 3\n",
      "sel : [4, 5, 6]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('01_chemvae': conda)"
  },
  "interpreter": {
   "hash": "111b6f304afb9dfb3ff29c259c88395a47b4de97d591c8d68e14d97f5211ad2a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}